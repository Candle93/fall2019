{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c13dcf535d5e76258b028bbd4627c794",
     "grade": false,
     "grade_id": "cell-f393e9f5396b08f6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 8 - Latent Variable Models\n",
    "For this week's assignment, you will implement a Gaussian Mixture Model and perform Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0262f9298d5aeaf9ca746cf003abafe",
     "grade": false,
     "grade_id": "cell-941db52bbe74f80d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster, datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9c5556358f21f1d971d2508d3099039c",
     "grade": false,
     "grade_id": "cell-5841abe9b5474ea2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 1. Load the Old Faithful dataset (1 pt)\n",
    "For this assignment, we will be working with the Old Faithful dataset. Old Faithful is a geyser that is found in Yellowstone National Park, Wyoming and is the park's most famous attraction. We will be working with a dataset from 1990 that recorded the time between eruptions and the duration of the eruption, both taken in minutes. There are 272 observations in total.\n",
    "\n",
    "We have provided the url to the dataset below. Use the pandas `read_csv()` function to read in the data. \n",
    "\n",
    "**NOTE:** you may want to use the `skipinitialspace` argument to properly load the header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1ce9605a2e8febf53347720e6f24a543",
     "grade": false,
     "grade_id": "cell-9ce296dedde4b74f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# URL for the dataset\n",
    "url = \"https://raw.githubusercontent.com/barneygovan/from-data-with-love/master/data/faithful.csv\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73461722bc3d86a2932eb830919b8bcd",
     "grade": true,
     "grade_id": "cell-7ee94fa68dd0a648",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert data.shape == (272, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42284794050dd254929ebdbd0023b9c3",
     "grade": false,
     "grade_id": "cell-8c9f78130f8d9b95",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 2: Visualize the data (1 pt)\n",
    "Let's get a sense of what our data look like by plotting the distribution of eruption times and waiting times, as well as a scatter plot of both dimensions.\n",
    "<ol>\n",
    "    <li>A histogram of the eruption time (the column labeled \"eruptions\").</li>\n",
    "    <li>A histogram of the waiting time between eruptions.</li>\n",
    "    <li>A scatter plot of both features</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f875acef68b6bbb7acf79e848d0fdfae",
     "grade": true,
     "grade_id": "cell-c9fcee0d9c5935b8",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b6e1cf73cf2e27be0845098406f420cb",
     "grade": false,
     "grade_id": "cell-60412ef641aa8221",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 3: Build a GMM (1 pt)\n",
    "Each feature seems to be bimodally distributes and the scatterplot clearly shows separation of two clusters. \n",
    "<ol>\n",
    "    <li> Using sklearn's `GaussianMixture` implementation, build a Gaussian Mixture Model with 2 Gaussians. Save the result in a variable named `gmm` <br>\n",
    "**Note:** In order for our assertions to work, make sure you use the default parameters for `GaussianMixture`, with the exception of random_state, which you should set to 126\n",
    "    </li>\n",
    "    <li> Annotate each datapoint using the `.predict` function \n",
    "    <li> Then create a scatterplot of eruption time versus waiting time in which each point is colored based on its prediction from the GMM</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a92aae11052ca01a3f7531fde7e38fb0",
     "grade": false,
     "grade_id": "cell-1a6509d9470ae7e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f187d954a1934f716dc5543f2da41f8c",
     "grade": true,
     "grade_id": "cell-adc61c99588dcb78",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert labels.shape == (272,)\n",
    "assert np.isclose(np.mean(labels), .64, .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2168174ea05aa59173c683283bb30c17",
     "grade": false,
     "grade_id": "cell-0b7b10ed69252dc8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 4: Choosing K (ungraded)\n",
    "As discussed in lecture, the Akaike information criterion (AIC) and the Bayesian information criterion (BIC) provide quantitative ways to choose the number of clusters that maximize the likelihood of our data while penalizing for increased complexity. Scikit-Learn's GMM estimator actually includes built-in methods that compute both of these.\n",
    "\n",
    "Let's look at the AIC and BIC as a function as the number of GMM components for our dataset. Run the cell below to visualize the AIC and BIC metrics for 10 different models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gaussians = np.arange(1, 10)\n",
    "\n",
    "# create a Gaussian mixture model for the range 1-10\n",
    "models = [GaussianMixture(n, random_state=126).fit(data)\n",
    "          for n in n_gaussians]\n",
    "\n",
    "# plot the AIC and BIC: uncomment the code below and run the cell\n",
    "\n",
    "# plt.plot(n_gaussians, [m.bic(data) for m in models], label='BIC')\n",
    "# plt.plot(n_gaussians, [m.aic(data) for m in models], label='AIC')\n",
    "# plt.legend(loc='best')\n",
    "# plt.xlabel('n_components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f559150c50381dcbad7783609a1d252",
     "grade": false,
     "grade_id": "cell-288ab4ab644fd173",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The optimal number of clusters is the value that minimizes the AIC or BIC. We can see from both of these measures that 2 seemed to be the right choice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53da85d0d2728636b9a42c09a9773359",
     "grade": false,
     "grade_id": "cell-dcffd8bdfe0eb8be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Task 5: Factor Analysis (1 pt)\n",
    "Factor analysis is useful technique for reducing dimensionality of data. It assumes that multiple observed variables have similar patterns of responses because they are all associated with a latent variable. \n",
    "\n",
    "Consumers (n = 99) rate on a scale of 0-100 how important they consider each of seven qualities when deciding whether\n",
    "or not to buy a 6-pack of beer: cost, volume, alcohol percentage, brewery reputation, the color, aroma, and taste. \n",
    "\n",
    "In future lectures, we will discuss how to go about choosing the right number of latent variables to use. However, for this assignment, we will perform factor analysis using 2 latent variables to see whether this data can be represented in 2 dimensions. \n",
    "\n",
    "Steps:\n",
    "<ol>\n",
    "    <li> Normalize the beer data using sklearn's `scale` function </li>\n",
    "    <li> Perform Factor Analysis using 2 components. Save the resulting model using the variable name `fa`</li>\n",
    "    <li> Observe the factor loadings, which you can access via the model's attribute `components_`. </li>\n",
    "    <li> (Optional) Visualize the factor loadings for each latent variable using a bar chart </li>\n",
    "</ol>\n",
    "\n",
    "**Note:** In order for our assertions to work, make sure you use the default parameters for GaussianMixture, with the exception of random_state, which you should set to 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "29501df12a6dc0331f539a594421bed3",
     "grade": false,
     "grade_id": "cell-0e5c27704d4bd093",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "beer = pd.read_csv(\"beer.txt\", sep=\"\\t\", dtype=np.float64)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2754c88e3a61034655e60017d5d06daa",
     "grade": true,
     "grade_id": "cell-4e7a6d78a0147e55",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(np.sum(fa.components_), -.618, .1)\n",
    "assert fa.components_.shape == (2, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
